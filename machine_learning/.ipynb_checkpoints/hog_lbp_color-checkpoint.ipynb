{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (50000, 32, 32, 3)\n",
      "y_train: (50000,)\n",
      "X_test: (10000, 32, 32, 3)\n",
      "y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "from data_utils import load_CIFAR10\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(\"cifar-10-batches-py\")\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 324)\n",
      "(10000, 324)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from skimage import color, exposure\n",
    "\n",
    "orie = 9\n",
    "ppc = (8,8)\n",
    "cpb = (2,2)\n",
    "tmp_train = []\n",
    "for i in xrange(X_train.shape[0]):\n",
    "    gray_img = color.rgb2gray(X_train[i])\n",
    "    fd = hog(gray_img, orientations=orie, pixels_per_cell=ppc,\n",
    "                    cells_per_block=cpb, visualise=False, transform_sqrt=True)\n",
    "    fd = fd[np.newaxis, :]\n",
    "    tmp_train.append(fd)\n",
    "hog_train = np.concatenate(tmp_train, axis=0)\n",
    "\n",
    "tmp_test = []\n",
    "for i in xrange(X_test.shape[0]):\n",
    "    gray_img = color.rgb2gray(X_test[i])\n",
    "    fd = hog(gray_img, orientations=orie, pixels_per_cell=ppc,\n",
    "                    cells_per_block=cpb, visualise=False, transform_sqrt=True)\n",
    "    fd = fd[np.newaxis, :]\n",
    "    tmp_test.append(fd)\n",
    "\n",
    "hog_test= np.concatenate(tmp_test, axis=0)\n",
    "\n",
    "print(hog_train.shape)\n",
    "print(hog_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 26)\n",
      "(10000, 26)\n"
     ]
    }
   ],
   "source": [
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "radius = 3\n",
    "n_points = 8 * radius\n",
    "METHOD = 'uniform'\n",
    "eps = 1e-7\n",
    "\n",
    "lbp_train = []\n",
    "for i in xrange(X_train.shape[0]):\n",
    "    gray_img = color.rgb2gray(X_train[i])\n",
    "    lbp = local_binary_pattern(gray_img, n_points, radius, METHOD)\n",
    "    h, _ = np.histogram(lbp.ravel(),bins=np.arange(0, n_points+3), range=(0, n_points+2))\n",
    "    h = h / (h.sum()+eps)\n",
    "    h = h[np.newaxis, :]\n",
    "    lbp_train.append(h)\n",
    "    \n",
    "lbp_train = np.concatenate(lbp_train, axis=0)\n",
    "\n",
    "lbp_test = []\n",
    "for i in xrange(X_test.shape[0]):\n",
    "    gray_img = color.rgb2gray(X_test[i])\n",
    "    lbp = local_binary_pattern(gray_img, n_points, radius, METHOD)\n",
    "    h, _ = np.histogram(lbp.ravel(),bins=np.arange(0, n_points+3), range=(0, n_points+2))\n",
    "    h = h / (h.sum()+eps)\n",
    "    h = h[np.newaxis, :]\n",
    "    lbp_test.append(h)\n",
    "\n",
    "lbp_test = np.concatenate(lbp_test, axis=0)\n",
    "\n",
    "print(lbp_train.shape)\n",
    "print(lbp_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 64)\n",
      "(10000, 64)\n"
     ]
    }
   ],
   "source": [
    "interv = 64\n",
    "data_train = X_train.copy()\n",
    "data_train = data_train.astype('uint8') // interv\n",
    "base = 256 // interv\n",
    "fea_train = []\n",
    "for i in xrange(data_train.shape[0]):\n",
    "    h = np.zeros((base**3,))\n",
    "    tmp = data_train[i].reshape(-1, 3)\n",
    "    tmp = tmp[:, 0]*base*base + tmp[:, 1]*base + tmp[:, 2]\n",
    "    uni, cnt = np.unique(tmp, return_counts=True)\n",
    "    h[uni] = cnt\n",
    "    h = h / h.sum()\n",
    "    h = h[np.newaxis, :]\n",
    "    fea_train.append(h)\n",
    "\n",
    "fea_train = np.concatenate(fea_train, axis=0)\n",
    "\n",
    "data_test = X_test.copy()\n",
    "data_test = data_test.astype('uint8') // interv\n",
    "fea_test = []\n",
    "for i in xrange(data_test.shape[0]):\n",
    "    h = np.zeros((base**3,))\n",
    "    tmp = data_test[i].reshape(-1, 3)\n",
    "    tmp = tmp[:, 0]*base*base + tmp[:, 1]*base + tmp[:, 2]\n",
    "    uni, cnt = np.unique(tmp, return_counts=True)\n",
    "    h[uni] = cnt\n",
    "    h = h / h.sum()\n",
    "    h = h[np.newaxis, :]\n",
    "    fea_test.append(h)\n",
    "\n",
    "fea_test = np.concatenate(fea_test, axis=0)\n",
    "\n",
    "print(fea_train.shape)\n",
    "print(fea_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 414)\n",
      "(10000, 414)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "data_train = np.concatenate([hog_train, lbp_train, fea_train], axis=1)\n",
    "data_test = np.concatenate([hog_test, lbp_test, fea_test], axis=1)\n",
    "\n",
    "with open('data_train.arr', 'wb') as handle:\n",
    "    pickle.dump(data_train, handle)\n",
    "\n",
    "with open('data_test.arr', 'wb') as handle:\n",
    "    pickle.dump(data_test, handle)\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3454)\n",
      "(10000, 3454)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('data_train.arr', 'rb') as handle:\n",
    "    data_train = pickle.load(handle)\n",
    "with open('data_test.arr', 'rb') as handle:\n",
    "    data_test = pickle.load(handle)\n",
    "\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a6a849f3bdfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdata_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/decomposition/pca.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/decomposition/pca.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;31m# Call different fits for either full or truncated SVD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msvd_solver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'full'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msvd_solver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'arpack'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'randomized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvd_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/decomposition/pca.pyc\u001b[0m in \u001b[0;36m_fit_full\u001b[0;34m(self, X, n_components)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_components\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mle'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mn_components\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0m_infer_dimension_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexplained_variance_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_components\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;31m# number of components for which the cumulated explained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/decomposition/pca.pyc\u001b[0m in \u001b[0;36m_infer_dimension_\u001b[0;34m(spectrum, n_samples, n_features)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_spectrum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_spectrum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mll\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_assess_dimension_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspectrum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/decomposition/pca.pyc\u001b[0m in \u001b[0;36m_assess_dimension_\u001b[0;34m(spectrum, rank, n_samples, n_features)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspectrum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             pa += log((spectrum[i] - spectrum[j]) *\n\u001b[0m\u001b[1;32m     87\u001b[0m                       (1. / spectrum_[j] - 1. / spectrum_[i])) + log(n_samples)\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=\"mle\")\n",
    "pca.fit(data_train)\n",
    "data_train = pca.transform(data_train)\n",
    "data_test = pca.transform(data_test)\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "import time \n",
    "\n",
    "group_K = [1, 3, 5, 20, 50, 100]\n",
    "acc = np.zeros((len(group_K),))\n",
    "#for i in xrange(len(group_K)):\n",
    "for i in range(1,100,2):\n",
    "    print(\"K: %d\" %i)\n",
    "    clf = neighbors.KNeighborsClassifier(group_K[i], n_jobs=-1)\n",
    "    clf.fit(data_train, y_train)\n",
    "    tic = time.time()\n",
    "    preds = clf.predict(data_test)\n",
    "    toc = time.time()\n",
    "    print(\"time for prediction: %d seconds\" %(toc-tic))\n",
    "\n",
    "    acc[i] = (preds==y_test).mean()\n",
    "    print(\"accuracy: \", acc[i])\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for training: 221 seconds\n",
      "time for prediction: 0 seconds\n",
      "train accuracy:  0.68418\n",
      "test accuracy:  0.6113\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "tic = time.time()\n",
    "lin_clf = svm.LinearSVC() \n",
    "\n",
    "lin_clf.fit(data_train, y_train)\n",
    "toc_1 = time.time()\n",
    "print(\"time for training: %d seconds\" %(toc_1-tic))\n",
    "\n",
    "preds_train = lin_clf.predict(data_train)\n",
    "acc_train = (preds_train==y_train).mean()\n",
    "\n",
    "preds_test = lin_clf.predict(data_test)\n",
    "acc_test = (preds_test==y_test).mean()\n",
    "toc_2 = time.time()\n",
    "print(\"time for prediction: %d seconds\" %(toc_2-toc_1))\n",
    "\n",
    "print(\"train accuracy: \", acc_train)\n",
    "print(\"test accuracy: \", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for training: 101 seconds\n",
      "time for prediction: 0 seconds\n",
      "train accuracy:  0.60714\n",
      "test accuracy:  0.5855\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "tic = time.time()\n",
    "lin_reg = linear_model.LogisticRegression(multi_class='multinomial', n_jobs=-1, solver='sag', max_iter=500)\n",
    "lin_reg.fit(data_train, y_train)\n",
    "toc_1 = time.time()\n",
    "print(\"time for training: %d seconds\" %(toc_1-tic))\n",
    "\n",
    "preds_train = lin_reg.predict(data_train)\n",
    "acc_train = (preds_train==y_train).mean()\n",
    "\n",
    "preds_test = lin_reg.predict(data_test)\n",
    "acc_test = (preds_test==y_test).mean()\n",
    "toc_2 = time.time()\n",
    "print(\"time for prediction: %d seconds\" %(toc_2-toc_1))\n",
    "\n",
    "print(\"train accuracy: \", acc_train)\n",
    "print(\"test accuracy: \", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for training: 3 seconds\n",
      "time for prediction: 0 seconds\n",
      "train accuracy:  0.67062\n",
      "test accuracy:  0.4267\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "tic = time.time()\n",
    "rf = RandomForestClassifier(max_depth = 12, min_samples_leaf = 15, n_jobs = -1, random_state=0)\n",
    "rf.fit(data_train,y_train)\n",
    "toc_1 = time.time()\n",
    "print(\"time for training: %d seconds\" %(toc_1-tic))\n",
    "\n",
    "preds = rf.predict(data_train)\n",
    "acc_train = (preds==y_train).mean()\n",
    "\n",
    "preds = rf.predict(data_test)\n",
    "acc_test = (preds==y_test).mean()\n",
    "toc_2 = time.time()\n",
    "print(\"time for prediction: %d seconds\" %(toc_2-toc_1))\n",
    "\n",
    "print(\"train accuracy: \", acc_train)\n",
    "print(\"test accuracy: \", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for training: 229 seconds\n",
      "time for prediction: 46 seconds\n",
      "train accuracy:  0.66918\n",
      "test accuracy:  0.616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import svm\n",
    "import time\n",
    "bag_clf = BaggingClassifier(base_estimator=svm.LinearSVC(), n_estimators=10, max_samples=0.7, max_features=0.7, n_jobs=-1)\n",
    "\n",
    "tic = time.time()\n",
    "bag_clf.fit(data_train, y_train)\n",
    "toc_1 = time.time()\n",
    "print(\"time for training: %d seconds\" %(toc_1-tic))\n",
    "preds = bag_clf.predict(data_train)\n",
    "acc_train = (preds==y_train).mean()\n",
    "\n",
    "preds = bag_clf.predict(data_test)\n",
    "acc_test = (preds==y_test).mean()\n",
    "toc_2 = time.time()\n",
    "print(\"time for prediction: %d seconds\" %(toc_2-toc_1))\n",
    "\n",
    "print(\"train accuracy: \", acc_train)\n",
    "print(\"test accuracy: \", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model\n",
    "import time\n",
    "\n",
    "tic = time.time()\n",
    "rf = RandomForestClassifier(max_depth = 12, min_samples_leaf = 15, n_jobs = -1)\n",
    "ada_clf = AdaBoostClassifier(base_estimator=rf, algorithm='SAMME')\n",
    "scores = cross_val_score(ada_clf, data_train, y_train,n_jobs=-1)\n",
    "toc_1 = time.time()\n",
    "print(\"time for training: %d seconds\" %(toc_1-tic))\n",
    "print(\"scores\",scores.mean()) \n",
    "\n",
    "preds = ada_clf.predict(data_train)\n",
    "acc_train = (preds==y_train).mean()\n",
    "\n",
    "preds = ada_clf.predict(data_test)\n",
    "acc_test = (preds==y_test).mean()\n",
    "toc_2 = time.time()\n",
    "print(\"time for prediction: %d seconds\" %(toc_2-toc_1))\n",
    "\n",
    "print(\"train accuracy: \", acc_train)\n",
    "print(\"test accuracy: \", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
